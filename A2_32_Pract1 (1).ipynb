{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name:Awez Sheikh\r\n",
    "### Roll No:32\r\n",
    "### Batch:A2\r\n",
    "## Practical 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7DrdNmYR5i_r"
   },
   "source": [
    "Task 1: Single perceptron Implementation:\n",
    "\n",
    "*   Write a python script to implement a single perceptron\n",
    "\n",
    "*   Include Functions for initialising weights and bias calculating the weighted sum applying activation function(e,g,step function)\n",
    "\n",
    "*   Test the perceptron on a simple binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1FYkB9O-6DwY"
   },
   "outputs": [],
   "source": [
    "x_input=[0.1,0.5,0.2]\n",
    "w_weight=[0.4,0.3,0.6]\n",
    "threshold=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "bRV6pfhL6lUx"
   },
   "outputs": [],
   "source": [
    "def step (weighted_sum):\n",
    "  if weighted_sum > threshold:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "x_PBDcLM64PQ"
   },
   "outputs": [],
   "source": [
    "def perceptron():\n",
    "  weighted_sum=0\n",
    "  for x,w in zip(x_input,w_weight):\n",
    "    weighted_sum += x*w\n",
    "    print(weighted_sum)\n",
    "  return step(weighted_sum)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SRYFJsKa7K2Q",
    "outputId": "ac511393-9c0b-439f-f634-97971c707027"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04000000000000001\n",
      "0.19\n",
      "0.31\n",
      "output= 0\n"
     ]
    }
   ],
   "source": [
    "output=perceptron()\n",
    "print(\"output=\" ,output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimised weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "g_NgoRuB7OAv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimised Weights (w1, w2, w3): [0.001, 0.005, 0.002]\n"
     ]
    }
   ],
   "source": [
    "x_input = [0.1, 0.5, 0.2]\n",
    "w_weight = [0, 0, 0]\n",
    "threshold = 0.5\n",
    "learning_rate = 0.01\n",
    "target = 1\n",
    "\n",
    "def step(weighted_sum):\n",
    "    return 1 if weighted_sum > threshold else 0\n",
    "\n",
    "def perceptron(x_input, w_weight, threshold, learning_rate, target):\n",
    "    weighted_sum = sum(x * w for x, w in zip(x_input, w_weight))\n",
    "    output = step(weighted_sum)\n",
    "    if output != target:\n",
    "        error = target - output\n",
    "        for i in range(len(w_weight)):\n",
    "            w_weight[i] += learning_rate * error * x_input[i]\n",
    "    return w_weight\n",
    "\n",
    "new_weights = perceptron(x_input, w_weight, threshold, learning_rate, target)\n",
    "print(f\"optimised Weights (w1, w2, w3): {new_weights}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### And gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(inputs_sum,threshold):\n",
    "    if inputs_sum >= threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def and_an(inputs):\n",
    "    inputs_sum=0\n",
    "    threshold=len(inputs)\n",
    "    for i in inputs:\n",
    "        inputs_sum+=i\n",
    "    return step(inputs_sum,threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0] 0\n",
      "[0, 1] 0\n",
      "[1, 0] 0\n",
      "[1, 1] 1\n"
     ]
    }
   ],
   "source": [
    "inputs =[[0,0],[0,1],[1,0],[1,1]]\n",
    "for input in inputs:\n",
    "    print(input,and_an(input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Or gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(inputs_sum,threshold):\n",
    "    if inputs_sum >= threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def or_an(inputs):\n",
    "    inputs_sum=0\n",
    "    threshold=1\n",
    "    for i in inputs:\n",
    "        inputs_sum+=i\n",
    "    return step(inputs_sum,threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0] 0\n",
      "[0, 1] 1\n",
      "[1, 0] 1\n",
      "[1, 1] 1\n"
     ]
    }
   ],
   "source": [
    "inputs =[[0,0],[0,1],[1,0],[1,1]]\n",
    "for input in inputs:\n",
    "    print(input,or_an(input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For three inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0] 0\n",
      "[0, 0, 1] 1\n",
      "[0, 1, 0] 1\n",
      "[0, 1, 1] 1\n",
      "[1, 0, 0] 1\n",
      "[1, 0, 1] 1\n",
      "[1, 1, 0] 1\n",
      "[1, 1, 1] 1\n"
     ]
    }
   ],
   "source": [
    "inputs =[[0,0,0],[0,0,1],[0,1,0],[0,1,1],[1,0,0],[1,0,1],[1,1,0],[1,1,1]]\n",
    "for input in inputs:\n",
    "    print(input,or_an(input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation Of Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def and_fun(inputs,weights):\n",
    "    inputs_sum=0\n",
    "    threshold=1\n",
    "    bias=-1\n",
    "    for i in range(len(inputs)):\n",
    "        inputs_sum+=inputs[i]*weights[i]\n",
    "    return step(inputs_sum + bias, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0] 0\n",
      "[0, 1] 0\n",
      "[1, 0] 0\n",
      "[1, 1] 1\n"
     ]
    }
   ],
   "source": [
    "inputs =[[0,0],[0,1],[1,0],[1,1]]\n",
    "weights=[1,1]\n",
    "for input in inputs:\n",
    "    print(input,and_fun(input,weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def or_fun(inputs,weights):\n",
    "    inputs_sum=0\n",
    "    threshold=0\n",
    "    bias=-1\n",
    "    for i in range(len(inputs)):\n",
    "        inputs_sum+=inputs[i]*weights[i]\n",
    "    return step(inputs_sum + bias, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0] 0\n",
      "[0, 1] 1\n",
      "[1, 0] 1\n",
      "[1, 1] 1\n"
     ]
    }
   ],
   "source": [
    "inputs =[[0,0],[0,1],[1,0],[1,1]]\n",
    "weights=[1,1]\n",
    "for input in inputs:\n",
    "    print(input,or_fun(input,weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement Perceptron learning algorithm for classification of following points (PO(-1,-1,-1), P1(-1,-1,1), P2(-1,1,-1), P3(-1,1,1),P4(1,-1,-1), P5(1,-1,1), P6(1,1,-1), P7(1,1,1)) into two classes: \n",
    "##### C1 = (P7 (1,1,1))  C2 = (PO(-1,-1,-1), P1(-1,-1,1), P2(-1,1,-1), P3(-1,1,1), P4(1,-1,-1), P5(1,-1,1), P6(1,1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned weights: [0.1 0.1 0.1]\n",
      "Learned bias: -0.30000000000000004\n",
      "Prediction for test point: 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([[-1, -1, -1], [-1, -1, 1], [-1, 1, -1], [-1, 1, 1],\n",
    "              [1, -1, -1], [1, -1, 1], [1, 1, -1], [1, 1, 1]])\n",
    "y = np.array([0, 0, 0, 0, 0, 0, 0, 1])\n",
    "\n",
    "w = np.zeros(3)\n",
    "b = 0\n",
    "\n",
    "def step(x):\n",
    "    return 1 if x >= 0 else 0\n",
    "\n",
    "learning_rate = 0.1\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range(len(X)):\n",
    "        weighted_sum = np.dot(X[i], w) + b\n",
    "        output = step(weighted_sum)\n",
    "        if output != y[i]:\n",
    "            w = w + learning_rate * (y[i] - output) * X[i]\n",
    "            b = b + learning_rate * (y[i] - output)\n",
    "\n",
    "print(\"Learned weights:\", w)\n",
    "print(\"Learned bias:\", b)\n",
    "\n",
    "test_point = np.array([1, 1, 1])\n",
    "prediction = step(np.dot(test_point, w) + b)\n",
    "print(\"Prediction for test point:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Results:\n",
      "Point [-1 -1 -1], True Label: 0, Predicted Label: 0\n",
      "Point [-1 -1  1], True Label: 0, Predicted Label: 1\n",
      "Point [-1  1 -1], True Label: 0, Predicted Label: 0\n",
      "Point [-1  1  1], True Label: 0, Predicted Label: 1\n",
      "Point [ 1 -1 -1], True Label: 0, Predicted Label: 0\n",
      "Point [ 1 -1  1], True Label: 0, Predicted Label: 1\n",
      "Point [ 1  1 -1], True Label: 0, Predicted Label: 0\n",
      "Point [1 1 1], True Label: 1, Predicted Label: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "points = np.array([\n",
    "    [-1, -1, -1],\n",
    "    [-1, -1, 1],\n",
    "    [-1, 1, -1],\n",
    "    [-1, 1, 1],\n",
    "    [1, -1, -1],\n",
    "    [1, -1, 1],\n",
    "    [1, 1, -1],\n",
    "    [1, 1, 1]\n",
    "])\n",
    "labels = np.array([-1, -1, -1, -1, -1, -1, -1, 1])\n",
    "labels = (labels + 1) // 2\n",
    "model_points = Sequential([\n",
    "    Dense(4, input_dim=3, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model_points.compile(optimizer=SGD(learning_rate=0.1), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_points.fit(points, labels, verbose=0, batch_size=len(points))  # Single pass with batch_size\n",
    "predictions_points = model_points.predict(points, verbose=0)\n",
    "predicted_classes_points = (predictions_points > 0.5).astype(int)\n",
    "print(\"\\nClassification Results:\")\n",
    "for i, point in enumerate(points):\n",
    "    print(f\"Point {point}, True Label: {labels[i]}, Predicted Label: {predicted_classes_points[i][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\n",
      "XOR Results:\n",
      "Input: [0 0], True Output: 0, Predicted Output: 0\n",
      "Input: [0 1], True Output: 1, Predicted Output: 1\n",
      "Input: [1 0], True Output: 1, Predicted Output: 1\n",
      "Input: [1 1], True Output: 0, Predicted Output: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "X = np.array([\n",
    "    [0, 0],\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [1, 1]\n",
    "])\n",
    "y = np.array([0, 1, 1, 0])  # XOR Output\n",
    "model_xor = Sequential([\n",
    "    Dense(8, input_dim=2, activation='relu'),  \n",
    "    Dense(4, activation='relu'),              \n",
    "    Dense(1, activation='sigmoid')           \n",
    "])\n",
    "model_xor.compile(optimizer=SGD(learning_rate=0.1), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_xor.fit(X, y, epochs=1000, verbose=0)\n",
    "predictions_xor = model_xor.predict(X)\n",
    "predicted_classes_xor = (predictions_xor > 0.5).astype(int)\n",
    "print(\"\\nXOR Results:\")\n",
    "for i, input_val in enumerate(X):\n",
    "    print(f\"Input: {input_val}, True Output: {y[i]}, Predicted Output: {predicted_classes_xor[i][0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a python code to find the number of linearly separable problems out of total binary classification problems on\n",
    "### points =(PO(-1,-1,-1), P1(-1,-1,1), P2(-1,1,-1), P3(-1,1,1),P4(1,-1,-1), P5(1,-1,1), P6(1,1,-1), P7(1,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of binary classification problems: 256\n",
      "Number of linearly separable problems: 104\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "def step(x):\n",
    "    return 1 if x >= 0 else 0\n",
    "\n",
    "def is_linearly_separable(X, y, w, b):\n",
    "    for i in range(len(X)):\n",
    "        if step(np.dot(X[i], w) + b) != y[i]:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "X = np.array([[-1, -1, -1], [-1, -1, 1], [-1, 1, -1], [-1, 1, 1],\n",
    "              [1, -1, -1], [1, -1, 1], [1, 1, -1], [1, 1, 1]])\n",
    "\n",
    "total_problems = 0\n",
    "linearly_separable_count = 0\n",
    "\n",
    "for i in range(2**8):\n",
    "  y = []\n",
    "  for j in range(8):\n",
    "    if (i >> j) & 1:\n",
    "        y.append(1)\n",
    "    else:\n",
    "        y.append(0)\n",
    "\n",
    "  y = np.array(y)\n",
    "  total_problems += 1\n",
    "\n",
    "  w = np.zeros(3)\n",
    "  b = 0\n",
    "  learning_rate = 0.1\n",
    "  epochs = 100\n",
    "  for epoch in range(epochs):\n",
    "      for k in range(len(X)):\n",
    "          weighted_sum = np.dot(X[k], w) + b\n",
    "          output = step(weighted_sum)\n",
    "          if output != y[k]:\n",
    "              w = w + learning_rate * (y[k] - output) * X[k]\n",
    "              b = b + learning_rate * (y[k] - output)\n",
    "\n",
    "  if is_linearly_separable(X, y, w, b):\n",
    "      linearly_separable_count +=1\n",
    "\n",
    "print(\"Total number of binary classification problems:\", total_problems)\n",
    "print(\"Number of linearly separable problems:\", linearly_separable_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nand gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAND Gate:\n",
      "Input: [0 0], Predicted Output: 1, Expected Output: 1\n",
      "Input: [0 1], Predicted Output: 1, Expected Output: 1\n",
      "Input: [1 0], Predicted Output: 1, Expected Output: 1\n",
      "Input: [1 1], Predicted Output: 0, Expected Output: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def step(x):\n",
    "    return 1 if x >= 0 else 0\n",
    "\n",
    "def train_perceptron(X, y, learning_rate=0.1, epochs=100):\n",
    "    w = np.zeros(X.shape[1]) \n",
    "    b = 0  \n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for k in range(len(X)):\n",
    "            weighted_sum = np.dot(X[k], w) + b\n",
    "            output = step(weighted_sum)\n",
    "            if output != y[k]:\n",
    "                w = w + learning_rate * (y[k] - output) * X[k]\n",
    "                b = b + learning_rate * (y[k] - output)\n",
    "\n",
    "    return w, b\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([1, 1, 1, 0])\n",
    "\n",
    "w, b = train_perceptron(X, y)\n",
    "\n",
    "print(\"NAND Gate:\")\n",
    "for i in range(len(X)):\n",
    "    weighted_sum = np.dot(X[i], w) + b\n",
    "    output = step(weighted_sum)\n",
    "    print(f\"Input: {X[i]}, Predicted Output: {output}, Expected Output: {y[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nor gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOR Gate:\n",
      "Input: [0 0], Predicted Output: 1, Expected Output: 1\n",
      "Input: [0 1], Predicted Output: 0, Expected Output: 0\n",
      "Input: [1 0], Predicted Output: 0, Expected Output: 0\n",
      "Input: [1 1], Predicted Output: 0, Expected Output: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def step(x):\n",
    "    return 1 if x >= 0 else 0\n",
    "\n",
    "def train_perceptron(X, y, learning_rate=0.1, epochs=100):\n",
    "    w = np.zeros(X.shape[1])  \n",
    "    b = 0  \n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for k in range(len(X)):\n",
    "            weighted_sum = np.dot(X[k], w) + b\n",
    "            output = step(weighted_sum)\n",
    "            if output != y[k]:\n",
    "                w = w + learning_rate * (y[k] - output) * X[k]\n",
    "                b = b + learning_rate * (y[k] - output)\n",
    "\n",
    "    return w, b\n",
    "\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([1, 0, 0, 0])\n",
    "\n",
    "w, b = train_perceptron(X, y)\n",
    "\n",
    "print(\"NOR Gate:\")\n",
    "for i in range(len(X)):\n",
    "    weighted_sum = np.dot(X[i], w) + b\n",
    "    output = step(weighted_sum)\n",
    "    print(f\"Input: {X[i]}, Predicted Output: {output}, Expected Output: {y[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xor gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XOR Gate:\n",
      "Input: [0 0], Predicted Output: 1, Expected Output: 0\n",
      "Input: [0 1], Predicted Output: 1, Expected Output: 1\n",
      "Input: [1 0], Predicted Output: 0, Expected Output: 1\n",
      "Input: [1 1], Predicted Output: 0, Expected Output: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def step(x):\n",
    "    return 1 if x >= 0 else 0\n",
    "\n",
    "def train_perceptron(X, y, learning_rate=0.1, epochs=100):\n",
    "    w = np.zeros(X.shape[1]) \n",
    "    b = 0  \n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for k in range(len(X)):\n",
    "            weighted_sum = np.dot(X[k], w) + b\n",
    "            output = step(weighted_sum)\n",
    "            if output != y[k]:\n",
    "                w = w + learning_rate * (y[k] - output) * X[k]\n",
    "                b = b + learning_rate * (y[k] - output)\n",
    "\n",
    "    return w, b\n",
    "\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([0, 1, 1, 0])\n",
    "\n",
    "w, b = train_perceptron(X, y)\n",
    "\n",
    "print(\"XOR Gate:\")\n",
    "for i in range(len(X)):\n",
    "    weighted_sum = np.dot(X[i], w) + b\n",
    "    output = step(weighted_sum)\n",
    "    print(f\"Input: {X[i]}, Predicted Output: {output}, Expected Output: {y[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xnor gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XNOR Gate:\n",
      "Input: [0 0], Predicted Output: 0, Expected Output: 1\n",
      "Input: [0 1], Predicted Output: 0, Expected Output: 0\n",
      "Input: [1 0], Predicted Output: 1, Expected Output: 0\n",
      "Input: [1 1], Predicted Output: 1, Expected Output: 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def step(x):\n",
    "    return 1 if x >= 0 else 0\n",
    "\n",
    "def train_perceptron(X, y, learning_rate=0.1, epochs=100):\n",
    "    w = np.zeros(X.shape[1]) \n",
    "    b = 0  \n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for k in range(len(X)):\n",
    "            weighted_sum = np.dot(X[k], w) + b\n",
    "            output = step(weighted_sum)\n",
    "            if output != y[k]:\n",
    "                w = w + learning_rate * (y[k] - output) * X[k]\n",
    "                b = b + learning_rate * (y[k] - output)\n",
    "\n",
    "    return w, b\n",
    "\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([1, 0, 0, 1])\n",
    "\n",
    "w, b = train_perceptron(X, y)\n",
    "\n",
    "print(\"XNOR Gate:\")\n",
    "for i in range(len(X)):\n",
    "    weighted_sum = np.dot(X[i], w) + b\n",
    "    output = step(weighted_sum)\n",
    "    print(f\"Input: {X[i]}, Predicted Output: {output}, Expected Output: {y[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
